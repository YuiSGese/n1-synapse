from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from typing import List, Optional
import os
from google import genai
from fastapi.middleware.cors import CORSMiddleware
from dotenv import load_dotenv
import json
import MeCab
import httpx # <--- D√πng c√°i n√†y thay cho supabase client

# Load bi·∫øn m√¥i tr∆∞·ªùng
load_dotenv(".env.local")

app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"], 
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# 1. C·∫•u h√¨nh Gemini
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
gemini_client = None
if GEMINI_API_KEY:
    try:
        gemini_client = genai.Client(api_key=GEMINI_API_KEY)
    except Exception as e:
        print(f"L·ªói Gemini: {e}")

# 2. C·∫•u h√¨nh Supabase (REST API)
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_KEY")

# 3. C·∫•u h√¨nh MeCab
try:
    tagger = MeCab.Tagger("-Owakati")
except Exception as e:
    tagger = None

class VocabRequest(BaseModel):
    word: str

class StoryRequest(BaseModel):
    vocab_list: List[str]
    topic: Optional[str] = "ƒë·ªùi th∆∞·ªùng"

class TokenizeRequest(BaseModel):
    text: str

def generate_content_with_fallback(prompt: str, preferred_model: str = 'gemini-2.0-flash'):
    # ... (Gi·ªØ nguy√™n h√†m fallback c≈© c·ªßa b·∫°n) ...
    models_to_try = [preferred_model, 'gemini-2.0-flash', 'gemini-1.5-flash', 'gemini-1.5-pro']
    last_error = None
    for model_id in models_to_try:
        try:
            print(f"üîÑ AI Try: {model_id}...")
            response = gemini_client.models.generate_content(model=model_id, contents=prompt)
            print(f"‚úÖ AI Success: {model_id}")
            return response
        except Exception as e:
            print(f"‚ùå AI Fail {model_id}: {e}")
            last_error = e
            continue
    if last_error: raise last_error

# --- ENDPOINTS ---

@app.get("/api/health")
def health_check():
    return {"status": "ok", "service": "N1 Synapse Backend (Cache Enabled via REST)"}

@app.post("/api/nlp/tokenize")
async def tokenize_text(req: TokenizeRequest):
    if not tagger: return {"tokens": [req.text]}
    try:
        parsed = tagger.parse(req.text).strip()
        tokens = [t for t in parsed.split(" ") if t.strip()]
        return {"tokens": tokens}
    except: return {"tokens": [req.text]}

# --- LOGIC TRA T·ª™ TH√îNG MINH (CACHE FIRST) ---
@app.post("/api/nlp/lookup")
async def lookup_word(req: VocabRequest):
    word = req.word.strip()
    
    # B∆Ø·ªöC 1: KI·ªÇM TRA DATABASE (CACHE) b·∫±ng REST API
    if SUPABASE_URL and SUPABASE_KEY:
        try:
            print(f"üîç Checking cache for: {word}")
            async with httpx.AsyncClient() as client:
                # G·ªçi Supabase REST API: GET /rest/v1/dictionary?word=eq.{word}
                response = await client.get(
                    f"{SUPABASE_URL}/rest/v1/dictionary",
                    params={"word": f"eq.{word}", "select": "*"},
                    headers={
                        "apikey": SUPABASE_KEY,
                        "Authorization": f"Bearer {SUPABASE_KEY}",
                    }
                )
                
                if response.status_code == 200:
                    data_list = response.json()
                    if data_list and len(data_list) > 0:
                        print("üéØ CACHE HIT! Tr·∫£ v·ªÅ ngay l·∫≠p t·ª©c.")
                        return data_list[0]
        except Exception as e:
            print(f"‚ö†Ô∏è Cache Error (Skipping): {e}")

    # B∆Ø·ªöC 2: N·∫æU KH√îNG C√ì -> H·ªéI GEMINI (MISS)
    if not gemini_client: raise HTTPException(status_code=500, detail="Ch∆∞a c·∫•u h√¨nh AI")
    
    try:
        print("ü§ñ Calling Gemini...")
        prompt = f"""
        B·∫°n l√† t·ª´ ƒëi·ªÉn N1. Ph√¢n t√≠ch t·ª´: {word}.
        Tr·∫£ v·ªÅ JSON thu·∫ßn t√∫y (kh√¥ng markdown):
        {{
            "reading": "Hiragana",
            "kanji_meaning": "√Çm H√°n Vi·ªát (n·∫øu c√≥, vi·∫øt HOA. VD: TI√äN SINH)",
            "meaning": "Nghƒ©a ti·∫øng Vi·ªát ng·∫Øn g·ªçn",
            "part_of_speech": "T·ª´ lo·∫°i",
            "example_sentence": "C√¢u v√≠ d·ª• ti·∫øng Nh·∫≠t N1 s·ªë 1",
            "example_translation": "D·ªãch nghƒ©a c√¢u v√≠ d·ª• 1",
            "example_sentence_2": "C√¢u v√≠ d·ª• ti·∫øng Nh·∫≠t N1 s·ªë 2 (ng·ªØ c·∫£nh kh√°c)",
            "example_translation_2": "D·ªãch nghƒ©a c√¢u v√≠ d·ª• 2"
        }}
        """
        response = generate_content_with_fallback(prompt, 'gemini-2.0-flash')
        clean_text = response.text.replace("```json", "").replace("```", "").strip()
        data = json.loads(clean_text)

        # B∆Ø·ªöC 3: L∆ØU V√ÄO DATABASE CHO L·∫¶N SAU (REST API)
        if SUPABASE_URL and SUPABASE_KEY:
            try:
                # Chu·∫©n b·ªã d·ªØ li·ªáu ƒë·ªÉ l∆∞u
                cache_entry = {
                    "word": word,
                    "reading": data.get("reading"),
                    "kanji_meaning": data.get("kanji_meaning"),
                    "meaning": data.get("meaning"),
                    "part_of_speech": data.get("part_of_speech"),
                    "example_sentence": data.get("example_sentence"),
                    "example_translation": data.get("example_translation"),
                    "example_sentence_2": data.get("example_sentence_2"),
                    "example_translation_2": data.get("example_translation_2")
                }
                
                async with httpx.AsyncClient() as client:
                    await client.post(
                        f"{SUPABASE_URL}/rest/v1/dictionary",
                        json=cache_entry,
                        headers={
                            "apikey": SUPABASE_KEY,
                            "Authorization": f"Bearer {SUPABASE_KEY}",
                            "Content-Type": "application/json",
                            "Prefer": "return=minimal" # Kh√¥ng c·∫ßn tr·∫£ v·ªÅ d·ªØ li·ªáu v·ª´a insert
                        }
                    )
                print("üíæ Saved to Cache.")
            except Exception as e:
                print(f"‚ö†Ô∏è Save Cache Error: {e}")

        return data

    except Exception as e:
        print(f"Fatal Lookup Error: {e}")
        return {"reading": "...", "meaning": "L·ªói AI", "example_sentence": "", "example_translation": ""}

@app.post("/api/ai/generate_story")
async def generate_story(req: StoryRequest):
    if not gemini_client: raise HTTPException(status_code=500, detail="Ch∆∞a c·∫•u h√¨nh AI")
    try:
        vocab_str = ", ".join(req.vocab_list)
        prompt = f"""
        Vi·∫øt m·ªôt c√¢u chuy·ªán ng·∫Øn ti·∫øng Nh·∫≠t (kho·∫£ng 200-300 ch·ªØ) ch·ªß ƒë·ªÅ '{req.topic}'.
        Y√™u c·∫ßu:
        1. S·ª≠ d·ª•ng T·∫§T C·∫¢ c√°c t·ª´: [{vocab_str}].
        2. In ƒë·∫≠m t·ª´ v·ª±ng b·∫±ng markdown (**t·ª´**).
        3. C√¢u chuy·ªán ph·∫£i LI·ªÄN M·∫†CH, LOGIC.
        4. T√°ch th√†nh t·ª´ng c√¢u v√† d·ªãch sang ti·∫øng Vi·ªát.
        Tr·∫£ v·ªÅ m·∫£ng JSON thu·∫ßn t√∫y: [{{ "jp": "...", "vi": "..." }}]
        """
        response = generate_content_with_fallback(prompt, 'gemini-2.0-flash')
        clean_text = response.text.replace("```json", "").replace("```", "").strip()
        return {"story": json.loads(clean_text)}
    except Exception as e:
        print(f"Story Error: {e}")
        raise HTTPException(status_code=500, detail="L·ªói t·∫°o truy·ªán")